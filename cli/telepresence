#!/usr/bin/env python3
"""
Telepresence CLI tool: local development environment for a remote
Kubernetes cluster.
"""

import argparse
import atexit
import json
import os
import os.path
import signal
import socket
import sys
from functools import wraps
from shutil import rmtree, copy
from subprocess import (
    check_output, Popen, CalledProcessError, check_call, TimeoutExpired,
    STDOUT, DEVNULL
)
from tempfile import mkdtemp, NamedTemporaryFile
from time import sleep, time
from traceback import print_exc
import webbrowser
from io import StringIO
from urllib.parse import quote_plus
unicode = str

# Don't modify next line without modifying corresponding line in
# .bumpversion.cfg:
__version__ = "0.36"
# Test runs can override version so we use specific custom Docker images:
if os.environ.get("TELEPRESENCE_VERSION") is not None:
    __version__ = os.environ["TELEPRESENCE_VERSION"]
REGISTRY = os.environ.get("TELEPRESENCE_REGISTRY", "datawire")


def random_name():
    """Return a random name for a container."""
    return "telepresence-{}-{}".format(time(), os.getpid()).replace(".", "-")


def find_free_port():
    """
    Find a port that isn't in use.

    XXX race condition-prone.
    """
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    try:
        s.bind(("127.0.0.1", 0))
        return s.getsockname()[1]
    finally:
        s.close()


class Runner(object):
    """Context for running subprocesses."""

    def __init__(self, logfile):
        """
        :param logfile: file-like object to write logs to.
        """
        self.logfile = logfile

    @classmethod
    def open(cls, logfile_path):
        """
        :return: File-like object for the given logfile path.
        """
        if logfile_path == "-":
            return cls(sys.stdout)
        else:
            # Wipe existing logfile, and use line buffering so data gets
            # written out immediately.
            if os.path.exists(logfile_path):
                os.remove(logfile_path)
            return cls(open(logfile_path, "a", buffering=1))

    def write(self, message):
        """Write a message to the log."""
        self.logfile.write(message)
        self.logfile.flush()

    def check_call(self, *args, **kwargs):
        """Run a subprocess, make sure it exited with 0."""
        self.write("Running: {}\n".format(args))
        check_call(
            *args,
            stdin=DEVNULL,
            stdout=self.logfile,
            stderr=self.logfile,
            **kwargs
        )

    def get_output(self, *args, **kwargs):
        """Return (stripped) command result as unicode string."""
        self.write("Running: {}\n".format(args))
        return unicode(
            check_output(*args, stdin=DEVNULL, stderr=self.logfile,
                         **kwargs).strip(), "utf-8"
        )

    def popen(self, *args, stdin=DEVNULL, **kwargs):
        """Return Popen object."""
        self.write("Running: {}\n".format(args))
        return Popen(
            *args,
            stdin=stdin,
            stderr=self.logfile,
            stdout=self.logfile,
            **kwargs
        )


def parse_args():
    """Create a new ArgumentParser and parse sys.argv."""
    parser = argparse.ArgumentParser(
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description=(
            "Telepresence: local development proxied to a remote Kubernetes "
            "cluster.\n\n"
            "Documentation: http://telepresence.io\n"
            "Real-time help: https://gitter.im/datawire/telepresence\n"
            "Issue tracker: https://github.com/datawire/telepresence/issues\n"
        )
    )
    parser.add_argument('--version', action='version', version=__version__)
    parser.add_argument(
        "--logfile",
        default="./telepresence.log",
        help=(
            "The path to write logs to. '-' means stdout, "
            "default is './telepresence.log'."
        )
    )
    group_deployment = parser.add_mutually_exclusive_group(required=True)
    group_deployment.add_argument(
        "--deployment",
        help=(
            "The name of the Kubernetes Deployment where the " +
            "datawire/telepresence-k8s image is running."
        )
    )
    group_deployment.add_argument(
        '--new-deployment',
        dest="new_deployment",
        help=(
            "Create a new Deployment in Kubernetes where the "
            "datawire/telepresence-k8s image will run."
        )
    )
    parser.add_argument(
        "--context",
        default=None,
        help=(
            "The Kubernetes context to use. Defaults to current kubectl"
            " context."
        )
    )
    parser.add_argument(
        "--namespace",
        default=None,
        help=(
            "The Kubernetes namespace to use. Defaults to kubectl's default"
            " for the current context, which is usually 'default'."
        )
    )
    parser.add_argument(
        "--expose",
        type=int,
        action='append',
        default=[],
        help=(
            "Port number in local container that will be " +
            "exposed to Kubernetes."
        )
    )
    parser.add_argument(
        "--run-shell",
        dest="runshell",
        action="store_true",
        required=True,
        help="Run a local shell that will be proxied to/from Kubernetes.",
    )
    return parser.parse_args()


def kubectl(context, namespace, args):
    """Return command-line for running kubectl."""
    result = ["kubectl"]
    if context is not None:
        result.extend(["--context", context])
    if namespace is not None:
        result.extend(["--namespace", namespace])
    result += args
    return result


class RemoteInfo(object):
    """
    Information about the remote setup.

    :ivar namespace str: The Kubernetes namespace.
    :ivar deployment_name str: The name of the Deployment object.
    :ivar pod_name str: The name of the pod created by the Deployment.
    :ivar deployment_config dict: The decoded k8s object (i.e. JSON/YAML).
    :ivar container_config dict: The container within the Deployment JSON.
    :ivar container_name str: The name of the container.
    """

    def __init__(
        self,
        runner,
        namespace,
        deployment_name,
        pod_name,
        deployment_config,
    ):
        self.namespace = namespace
        self.deployment_name = deployment_name
        self.pod_name = pod_name
        self.deployment_config = deployment_config
        cs = deployment_config["spec"]["template"]["spec"]["containers"]
        self.container_config = [
            c for c in cs if "telepresence-k8s" in c["image"]
        ][0]
        self.container_name = self.container_config["name"]

    def remote_telepresence_version(self):
        """Return the version used by the remote Telepresence container."""
        return self.container_config["image"].split(":")[-1]


def _get_service_names(environment):
    """Return names of Services, as used in env variable names."""
    # Order matters for service_keys, need it to be consistent with port
    # forwarding order in remote container.
    result = [
        key[:-len("_SERVICE_HOST")] for key in environment
        if key.endswith("_SERVICE_HOST")
    ]
    result.sort()
    return result


def _get_remote_env(runner, context, namespace, pod_name, container_name):
    """Get the environment variables in the remote pod."""
    env = runner.get_output(
        kubectl(
            context, namespace,
            ["exec", pod_name, "--container", container_name, "env"]
        )
    )
    result = {}
    for line in env.splitlines():
        key, value = line.split("=", 1)
        result[key] = value
    return result


def get_deployment_set_keys(remote_info):
    """Get the set of environment variables names set by the Deployment."""
    return set(
        [var["name"] for var in remote_info.container_config.get("env", [])]
    )


def get_env_variables(runner, remote_info, context):
    """
    Generate environment variables that match kubernetes.
    """
    # Get the environment:
    remote_env = _get_remote_env(
        runner, context, remote_info.namespace, remote_info.pod_name,
        remote_info.container_name
    )
    service_names = _get_service_names(remote_env)
    deployment_set_keys = get_deployment_set_keys(remote_info)
    # Tell local process about the remote setup, useful for testing and
    # debugging:
    socks_result = {
        "TELEPRESENCE_POD": remote_info.pod_name,
        "TELEPRESENCE_CONTAINER": remote_info.container_name
    }
    # ips proxied via socks, can copy addresses unmodified:
    for key, value in remote_env.items():
        if key in deployment_set_keys:
            # Copy over Deployment-set env variables:
            socks_result[key] = value
        for service_name in service_names:
            # Copy over Service env variables to SOCKS variant:
            if key.startswith(service_name + "_") and (
                key.endswith("_ADDR") or key.endswith("_PORT") or
                key.endswith("_PROTO") or key.endswith("_HOST") or
                key.endswith("_TCP")
            ):
                socks_result[key] = value
    return socks_result


def get_remote_info(runner, deployment_name, context, namespace):
    """Given the deployment name, return a RemoteInfo object."""
    deployment = json.loads(
        runner.get_output(
            kubectl(
                context, namespace, [
                    "get",
                    "deployment",
                    "-o",
                    "json",
                    deployment_name,
                    "--export",
                ]
            )
        )
    )
    expected_metadata = deployment["spec"]["template"]["metadata"]
    runner.write("Expected metadata for pods: {}\n".format(expected_metadata))
    pods = json.loads(
        runner.get_output(
            kubectl(context, namespace,
                    ["get", "pod", "-o", "json", "--export"])
        )
    )["items"]

    for pod in pods:
        name = pod["metadata"]["name"]
        phase = pod["status"]["phase"]
        runner.write(
            "Checking {} (phase {})...\n".
            format(pod["metadata"].get("labels"), phase)
        )
        if not set(expected_metadata.get("labels", {}).items()
                   ).issubset(set(pod["metadata"].get("labels", {}).items())):
            runner.write("Labels don't match.\n")
            continue
        # Metadata for Deployment will hopefully have a namespace. If not, fall
        # back to one we were given. If we weren't given one, best we can do is
        # choose "default".
        if (name.startswith(deployment_name + "-")
            and
            pod["metadata"]["namespace"] == deployment["metadata"].get(
                "namespace", namespace or "default")
            and
            phase in (
                "Pending", "Running"
        )):
            runner.write("Looks like we've found our pod!\n")
            remote_info = RemoteInfo(
                runner,
                namespace,
                deployment_name,
                name,
                deployment,
            )
            # Ensure remote container is running same version as we are:
            if remote_info.remote_telepresence_version() != __version__:
                raise SystemExit((
                    "The remote datawire/telepresence-k8s container is " +
                    "running version {}, but this tool is version {}. " +
                    "Please make sure both are running the same version."
                ).format(
                    remote_info.remote_telepresence_version(), __version__
                ))
            # Wait for pod to be running:
            wait_for_pod(runner, remote_info, context)
            return remote_info

    raise RuntimeError(
        "Telepresence pod not found for Deployment '{}'.".
        format(deployment_name)
    )


def ssh(runner, ssh_port, args):
    """Connect to remote pod via SSH.

    Returns Popen object.
    """
    return runner.popen([
        "ssh",
        # SSH with no warnings:
        "-q",
        # Don't validate host key:
        "-oStrictHostKeyChecking=no",
        # Don't store host key:
        "-oUserKnownHostsFile=/dev/null",
        # Ping once a second; after three retries will disconnect:
        "-oServerAliveInterval=1",
        # No shell:
        "-N",
        "-p",
        str(ssh_port),
        "root@localhost",
    ] + args)


def wait_for_ssh(runner, ssh_port):
    for i in range(30):
        try:
            runner.check_call([
                "ssh", "-q", "-p", str(ssh_port), "-oStrictHostKeyChecking=no",
                "-oUserKnownHostsFile=/dev/null", "root@localhost", "/bin/true"
            ])
        except CalledProcessError:
            sleep(1)
        else:
            return
    raise RuntimeError("SSH isn't starting.")


def wait_for_pod(runner, remote_info, context):
    for i in range(120):
        try:
            pod = json.loads(
                runner.get_output(
                    kubectl(
                        context, remote_info.namespace,
                        ["get", "pod", remote_info.pod_name, "-o", "json"]
                    )
                )
            )
        except CalledProcessError:
            sleep(1)
            continue
        if pod["status"]["phase"] == "Running":
            for container in pod["status"]["containerStatuses"]:
                if container["name"] == remote_info.container_name and (
                    container["ready"]
                ):
                    return
        sleep(1)
    raise RuntimeError(
        "Pod isn't starting or can't be found: {}".format(pod["status"])
    )


def connect(
    runner,
    remote_info,
    local_exposed_ports,
    context,
):
    """
    Start all the processes that handle remote proxying.

    Return list of Popen instances.
    """
    processes = []
    ssh_port = find_free_port()

    # forward remote port to here, by tunneling via remote SSH server:
    processes.append(
        runner.popen(
            kubectl(
                context, remote_info.namespace, [
                    "port-forward", remote_info.pod_name,
                    "{}:22".format(ssh_port)
                ]
            )
        )
    )
    atexit.register(killall, processes)
    wait_for_ssh(runner, ssh_port)

    for port_number in local_exposed_ports:
        processes.append(
            ssh(
                runner, ssh_port,
                ["-R", "*:{}:127.0.0.1:{}".format(port_number, port_number)]
            )
        )

    # start tunnel to remote SOCKS proxy, for telepresence --run.
    socks_port = find_free_port()
    processes.append(
        ssh(
            runner, ssh_port,
            ["-L", "127.0.0.1:{}:127.0.0.1:9050".format(socks_port)]
        ),
    )

    return processes, socks_port, ssh_port


def killall(processes):
    for p in processes:
        if p.poll() is None:
            p.terminate()
    for p in processes:
        try:
            p.wait(timeout=1)
        except TimeoutExpired:
            p.kill()
            p.wait()


def start_proxy(runner, args):
    """Start the kubectl port-forward and SSH clients that do the proxying."""
    if sys.stderr.isatty():
        print("Starting proxy...", file=sys.stderr)
    if args.deployment is None:
        # This implies --new-deployment:
        args.deployment = args.new_deployment

        def remove_existing_deployment():
            runner.get_output(
                kubectl(
                    args.context, args.namespace, [
                        "delete", "--ignore-not-found", "service,deployment",
                        args.deployment
                    ]
                )
            )

        atexit.register(remove_existing_deployment)
        remove_existing_deployment()
        command = kubectl(
            args.context, args.namespace, [
                "run",
                "--generator",
                "deployment/v1beta1",
                args.deployment,
                "--image={}/telepresence-k8s:{}".format(REGISTRY, __version__),
            ]
        )
        for port in args.expose:
            command.append("--port={}".format(port))
        if args.expose:
            command.append("--expose")
        runner.get_output(command)

    remote_info = get_remote_info(runner, args.deployment,
                                  args.context, args.namespace)

    processes, socks_port, ssh_port = connect(
        runner,
        remote_info,
        args.expose,
        args.context,
    )
    sleep(5)  # wait for SSH proxies to go live

    # Get the environment variables we want to copy from the remote pod:
    env = get_env_variables(runner, remote_info, args.context)

    return processes, env, socks_port, ssh_port, remote_info


TORSOCKS_CONFIG = """
# Allow process to listen on ports:
AllowInbound 1
# Allow process to connect to localhost:
AllowOutboundLocalhost 1
# Connect to custom port for SOCKS server:
TorPort {}
"""


def sip_workaround():
    """
    Workaround System Integrity Protection.

    Newer OS X don't allow injecting libraries into binaries in /bin, /sbin and
    /usr. We therefore make a copy of them and modify $PATH to point at their
    new location. It's only ~100MB so this should be pretty fast!
    """
    protected = {"/bin", "/sbin", "/usr/sbin", "/usr/bin"}
    # Remove protected paths from $PATH:
    paths = [p for p in os.environ["PATH"].split(":") if p not in protected]
    # Add temp dir
    bin_dir = mkdtemp()
    paths.insert(0, bin_dir)
    atexit.register(rmtree, bin_dir)
    for directory in protected:
        for file in os.listdir(directory):
            try:
                copy(os.path.join(directory, file), bin_dir)
            except IOError:
                continue
            os.chmod(os.path.join(bin_dir, file), 0o775)
    # Return new $PATH
    return ":".join(paths)


def wait_for_exit(runner, shell_process, processes):
    """Given Popens, wait for one of them to die."""
    while True:
        sleep(0.1)
        if shell_process.poll() is not None:
            # Shell exited, we're done. Automatic shutdown cleanup will kill
            # subprocesses.
            raise SystemExit(shell_process.poll())
        for p in processes:
            code = p.poll()
            if code is not None:
                if sys.stderr.isatty:
                    runner.write(
                        "A subprocess died, killing all processes...\n"
                    )
                killall(processes)
                # Unfortunatly torsocks doesn't deal well with connections
                # being lost, so best we can do is shut down.
                if sys.stderr.isatty:
                    print(
                        "Proxy to Kubernetes exited. This is typically due to"
                        " a lost connection.",
                        file=sys.stderr
                    )
                raise SystemExit(3)


def mount_remote_volumes(runner, remote_info, ssh_port):
    """
    sshfs is used to mount the remote system locally.
    """
    mount_dir = mkdtemp()
    runner.check_call([
        "sshfs",
        "-p",
        str(ssh_port),
        # Don't validate host key:
        "-o",
        "StrictHostKeyChecking=no",
        # Don't store host key:
        "-o",
        "UserKnownHostsFile=/dev/null",
        "root@localhost:/",
        mount_dir
    ])
    return mount_dir


def run_local_command(
    runner, remote_info, args, env_overrides, subprocesses, socks_port,
    ssh_port
):
    """--run support, run command locally."""
    env = os.environ.copy()
    env.update(env_overrides)
    # Create custom torsocks.conf, since some options we want (in particular,
    # port) aren't accessible via env variables in older versions of torconf:
    with NamedTemporaryFile(mode="w+", delete=False) as tor_conffile:
        tor_conffile.write(TORSOCKS_CONFIG.format(socks_port))
    env["TORSOCKS_CONF_FILE"] = tor_conffile.name
    if runner.logfile is not sys.stdout:
        env["TORSOCKS_LOG_FILE_PATH"] = runner.logfile.name
    # Don't use runner.popen() since we want to give program access to current
    # stdout and stderr if it wants it.
    env["PROMPT_COMMAND"] = (
        'PS1="@{}|$PS1";unset PROMPT_COMMAND'.format(
            args.context or
            runner.get_output(["kubectl", "config", "current-context"]).strip()
        )
    )
    # Make sure we use "bash", no "/bin/bash", so we get the copied version on
    # OS X:
    if sys.platform == "darwin":
        env["PATH"] = sip_workaround()
    mount_dir = mount_remote_volumes(runner, remote_info, ssh_port)
    env["TELEPRESENCE_ROOT"] = mount_dir
    p = Popen(["torsocks", "bash"], env=env)

    def terminate_if_alive():
        runner.write("Shutting down local shell...\n")
        os.remove(tor_conffile.name)
        if p.poll() is None:
            runner.write("Killing local shell...\n")
            p.terminate()
            p.wait()
        if sys.platform.startswith("linux"):
            runner.get_output(["fusermount", "-u", mount_dir])
        else:
            runner.get_output(["umount", mount_dir])
        os.rmdir(mount_dir)

    atexit.register(terminate_if_alive)
    wait_for_exit(runner, p, subprocesses)


BUG_REPORT_TEMPLATE = u"""\
### What were you trying to do?

(please tell us)

### What did you expect to happen?

(please tell us)

### What happened instead?

(please tell us - the traceback is automatically included, see below)

### Automatically included information

Command line: `{}`
Version: `{}`
Python version: `{}`
kubectl version: `{}`
OS: `{}`
Traceback:

```
{}
```

Logs:

```
{}
```
"""


def read_logs(logfile):
    """Read logfile, return string."""
    logs = "Not available"
    if logfile != "-" and os.path.exists(logfile):
        try:
            with open(logfile, "r") as logfile:
                logs = logfile.read()
        except Exception as e:
            logs += ", error ({})".format(e)
    return logs


class handle_unexpected_errors(object):
    """Decorator that catches unexpected errors."""

    def __init__(self, logfile):
        self.logfile = logfile

    def __call__(self, f):
        def safe_output(args):
            try:
                return unicode(check_output(args), "utf-8").strip()
            except CalledProcessError as e:
                return "(error: {})".format(e)

        @wraps(f)
        def call_f(*args, **kwargs):
            try:
                return f(*args, **kwargs)
            except SystemExit:
                raise
            except KeyboardInterrupt:
                raise SystemExit(0)
            except Exception as e:
                logs = read_logs(self.logfile)
                errorf = StringIO()
                print_exc(file=errorf)
                error = errorf.getvalue()
                print(
                    "\nLooks like there's a bug in our code. Sorry about that!"
                    "\n\n"
                    "Here's the traceback:\n\n" + error + "\n"
                )
                if self.logfile != "-":
                    print(
                        "And here are the last few lines of the logfile "
                        "(see {} for the complete logs):\n\n".format(
                            self.logfile
                        ) + "\n".join(logs.splitlines()[-20:]) + "\n"
                    )

                if input(
                    "Would you like to file an issue in our issue tracker?"
                    " We'd really appreciate the help improving our "
                    "product. [Y/n]: ",
                ).lower() in ("y", ""):
                    url = (
                        "https://github.com/datawire/telepresence/issues/" +
                        "new?body="
                    )
                    body = quote_plus(
                        # Overly long URLs won't work:
                        BUG_REPORT_TEMPLATE.format(
                            sys.argv, __version__, sys.version,
                            safe_output([
                                "kubectl", "version", "--short", "--client"
                            ]),
                            safe_output(["uname", "-a"]), error, logs[-1000:]
                        )[:4000]
                    )
                    webbrowser.open_new(url + body)
                else:
                    raise SystemExit(1)

        return call_f


def require_command(runner, command, message=None):
    if message is None:
        message = "Please install " + command
    try:
        runner.get_output(["which", command])
    except CalledProcessError as e:
        sys.stderr.write(message + "\n")
        sys.stderr.write(
            "See the documentation at http://telepresence.io "
            "for more details.\n"
        )
        raise SystemExit(1)


def main():
    # Make SIGTERM do clean shutdown (in particular, we want atexit functions
    # to be called):
    def shutdown(signum, frame):
        raise SystemExit(0)

    signal.signal(signal.SIGTERM, shutdown)

    args = parse_args()
    runner = Runner.open(args.logfile)

    @handle_unexpected_errors(args.logfile)
    def go():
        # Make sure we can access Kubernetes:
        try:
            runner.get_output(["kubectl", "cluster-info"])
        except (CalledProcessError, OSError, IOError) as e:
            sys.stderr.write("Error accessing Kubernetes: {}\n".format(e))
            raise SystemExit(1)
        # Make sure we can run openssh:
        try:
            runner.write("Running 'ssh -V'...")
            version = check_output(["ssh", "-V"], stdin=DEVNULL, stderr=STDOUT)
            if not version.startswith(b"OpenSSH"):
                raise SystemExit(
                    "'ssh' is not the OpenSSH client, apparently."
                )
        except (CalledProcessError, OSError, IOError) as e:
            sys.stderr.write("Error running ssh: {}\n".format(e))
            raise SystemExit(1)
        # Other requirements:
        require_command(
            runner, "torsocks", "Please install torsocks (v2.1 or later)"
        )
        require_command(runner, "sshfs")
        subprocesses, env, socks_port, ssh_port, remote_info = start_proxy(
            runner, args
        )
        run_local_command(
            runner, remote_info, args, env, subprocesses, socks_port, ssh_port
        )

    go()


if __name__ == '__main__':
    main()
